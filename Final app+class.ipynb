{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e479f0d2",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e453ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please run the class first and then app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c318fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip statements to install dependencies in case its missing\n",
    "\n",
    "# for SentenceTransformer\n",
    "pip install sentence-transformers\n",
    "\n",
    "# for dash and its components\n",
    "pip install dash dash-core-components dash-html-components dash-table jupyter-dash\n",
    "\n",
    "# for pandas, sklearn, scipy, fuzzywuzzy and nltk\n",
    "pip install pandas scikit-learn scipy fuzzywuzzy nltk numpy plotly\n",
    "\n",
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915e0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cdist\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class StringMatching:\n",
    "    def __init__(self, source, target):\n",
    "        # default column pairings\n",
    "        self.default_source_cols = ['Variable', 'Label', 'Definition (derived Vars)']\n",
    "        self.default_target_cols = ['Variable', 'Label', 'Rule for derivation']\n",
    "\n",
    "        source_cols = [col for col in self.default_source_cols if col in source.columns]\n",
    "        target_cols = [col for col in self.default_target_cols if col in target.columns]\n",
    "\n",
    "        self.source = source.dropna(subset=source_cols)\n",
    "        self.target = target.dropna(subset=target_cols)\n",
    "        \n",
    "        self.model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "        # Calculate the embeddings for cleaned data\n",
    "        self.source_embeddings = self.get_embeddings(self.clean_data(self.source[source_cols]))\n",
    "        self.target_embeddings = self.get_embeddings(self.clean_data(self.target[target_cols]))\n",
    "\n",
    "        # For tfidf similarity\n",
    "        self.corpus = pd.concat([self.source[source_cols], self.target[target_cols]])\n",
    "        self.corpus = self.corpus.replace(np.nan, '').dropna()\n",
    "        self.tfidf_vectorizer = TfidfVectorizer().fit(self.corpus)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_data(data):\n",
    "        stop_words = ['a', 'an', 'the', 'in', 'on', 'of', 'and', 'or', 'is', 'are', 'to', 'for', 'it', 'that', 'this']\n",
    "        stop_words += ['<', '%', ':', '&']  # Add any additional stopwords specific to your data\n",
    "        return [' '.join([word for word in str(row).lower().split() if word not in stop_words]) for row in data]\n",
    "\n",
    "    def get_embeddings(self, data):\n",
    "        return self.model.encode(data)  \n",
    "    #below are the NLP methods\n",
    "    @staticmethod\n",
    "    def similarity_token_sort(str1, str2):\n",
    "        score = fuzz.token_sort_ratio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def similarity_ratio(str1, str2):\n",
    "        score = fuzz.ratio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def similarity_partial_ratio(str1, str2):\n",
    "        score = fuzz.partial_ratio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def similarity_token_sort_ratio(str1, str2):\n",
    "        score = fuzz.token_sort_ratio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def similarity_token_set_ratio(str1, str2):\n",
    "        score = fuzz.token_set_ratio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def similarity_partial_token_set_ratio(str1, str2):\n",
    "        score = fuzz.partial_token_set_ratio(str1, str2)\n",
    "        return score\n",
    "    @staticmethod\n",
    "    def similarity_partial_token_sort_ratio(str1, str2):\n",
    "        score = fuzz.partial_token_sort_ratio(str1, str2)\n",
    "        return score\n",
    "    @staticmethod\n",
    "    def QRatio(str1, str2):\n",
    "        score = fuzz.QRatio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def UQRatio(str1, str2):\n",
    "        score = fuzz.UQRatio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def UWRatio(str1, str2):\n",
    "        score = fuzz.UWRatio(str1, str2)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def WRatio(str1, str2):\n",
    "        score = fuzz.WRatio(str1, str2)\n",
    "        return score\n",
    "    \n",
    "    def tfidf_similarity(self, text1, text2):\n",
    "        tfidf1 = self.tfidf_vectorizer.transform([text1])\n",
    "        tfidf2 = self.tfidf_vectorizer.transform([text2])\n",
    "        return cosine_similarity(tfidf1, tfidf2)[0][0]\n",
    "    \n",
    "    def bert_similarity(self, text1, text2):\n",
    "        embeddings1 = self.get_embeddings(self.clean_data([text1]))\n",
    "        embeddings2 = self.get_embeddings(self.clean_data([text2]))\n",
    "        # We use cosine distance, so we subtract from 1 to get similarity\n",
    "        similarity = 1 - cdist(embeddings1, embeddings2, 'cosine')[0][0]\n",
    "        return similarity\n",
    "\n",
    " #method that does the calcualtions and filetring based on user input \n",
    "    def multi_score(self, n, similarity_func, source_cols=None, target_cols=None, source_filter=None, \n",
    "                source_file_name=\"Source\", target_file_name=\"Target\"):\n",
    "        matches = []\n",
    "        source_df = self.source\n",
    "        target_df = self.target\n",
    "        # Strip white spaces from object type columns\n",
    "        source_df = source_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "        # Use default columns if none provided\n",
    "        if source_cols is None:\n",
    "            source_cols = ['Variable', 'Label', 'Definition (derived Vars)']\n",
    "\n",
    "        if target_cols is None:\n",
    "            target_cols = ['Variable', 'Label', 'Rule for derivation']\n",
    "\n",
    "        # If a filter is provided, apply it to the source dataframe\n",
    "        if source_filter is not None:\n",
    "            col, val = source_filter\n",
    "            source_df = source_df[source_df[col] == val]\n",
    "\n",
    "        for _, row1 in source_df.iterrows():\n",
    "            data1 = [row1[col] for col in source_cols]\n",
    "            scores = []\n",
    "\n",
    "            for _, row2 in target_df.iterrows():\n",
    "                data2 = [row2[col] for col in target_cols]\n",
    "                scores.append(tuple(similarity_func(d1, d2) for d1, d2 in zip(data1, data2)))\n",
    "\n",
    "            scores_sorted = sorted(enumerate(scores), key=lambda x: sum(x[1]), reverse=True)\n",
    "\n",
    "            if scores_sorted:\n",
    "                top_matches = [tuple(data1) + tuple(target_df.iloc[idx][target_cols]) + tuple(score) \n",
    "                               for idx, score in scores_sorted[:n]]\n",
    "                matches.extend(top_matches)\n",
    "\n",
    "        columns = [f'{source_file_name} {col}' for col in source_cols] + \\\n",
    "                   [f'{target_file_name} {col}' for col in target_cols] + \\\n",
    "                   [f'{source_file_name} {s_col} - {target_file_name} {t_col} Score' \n",
    "                    for s_col, t_col in zip(source_cols, target_cols)]\n",
    "        result_df = pd.DataFrame(matches, columns=columns)\n",
    "\n",
    "        # Filter the columns that end with \"Score\" and plot them\n",
    "        score_columns = [col for col in result_df.columns if col.endswith('Score')]\n",
    "        scores_plot = go.Figure()\n",
    "        for col in score_columns:\n",
    "            for source_col, target_col in zip(source_cols, target_cols):\n",
    "                scores_plot.add_trace(go.Scatter(\n",
    "                    x=result_df[col].tolist(),\n",
    "                    y=result_df[f'{source_file_name} {source_col}'].tolist(),\n",
    "                    name=f'{source_col} - {target_col}',\n",
    "                    hoverinfo='text',\n",
    "                    text=[f'{source_file_name}: {source_value}<br>{target_file_name}: {target_value}' \n",
    "                          for source_value, target_value in zip(\n",
    "                              result_df[f'{source_file_name} {source_col}'].tolist(), \n",
    "                              result_df[f'{target_file_name} {target_col}'].tolist()\n",
    "                          )]\n",
    "                ))\n",
    "\n",
    "        scores_plot.update_layout(\n",
    "            title=\"Scores for Similarity Functions\",\n",
    "            xaxis_title=f\"{source_file_name} - {target_file_name} Scores\",\n",
    "            yaxis_title=\"Score\",\n",
    "            hovermode=\"closest\",\n",
    "            barmode=\"group\"\n",
    "        )\n",
    "\n",
    "        return result_df, scores_plot\n",
    "    \n",
    "   \n",
    "    #calucalte similiarty scores based on what function is selected\n",
    "    def similarity_scores(self, n):\n",
    "        similarity_functions = [\n",
    "            ('similarity_ratio', self.similarity_ratio),\n",
    "            ('similarity_partial_ratio', self.similarity_partial_ratio),\n",
    "            ('similarity_token_sort_ratio', self.similarity_token_sort_ratio),\n",
    "            ('similarity_token_set_ratio', self.similarity_token_set_ratio),\n",
    "            ('similarity_partial_token_set_ratio', self.similarity_partial_token_set_ratio),\n",
    "            ('similarity_partial_token_sort_ratio', self.similarity_partial_token_sort_ratio),\n",
    "            ('QRatio', self.QRatio),\n",
    "            ('UQRatio', self.UQRatio),\n",
    "            ('UWRatio', self.UWRatio),\n",
    "            ('WRatio', self.WRatio),\n",
    "            ('tfidf_similarity', self.tfidf_similarity) \n",
    "            #,('bert_similarity', self.bert_similarity)\n",
    "        ]\n",
    "\n",
    "        # Dataframe to hold the results\n",
    "        scores_df = pd.DataFrame()\n",
    "\n",
    "        for _, row1 in self.df1.iterrows():\n",
    "            var1, label1 = row1['Variable'], row1['Label']\n",
    "            matched_vars = []\n",
    "            matched_labels = []\n",
    "\n",
    "            for _, row2 in self.df2.iterrows():\n",
    "                var2, label2 = row2['Variable'], row2['Label']\n",
    "                scores = {}\n",
    "\n",
    "                for func_name, similarity_func in similarity_functions:\n",
    "                    label_score = similarity_func(label1, label2)\n",
    "                    scores[func_name] = label_score\n",
    "\n",
    "                # Add the variable and matched variable to the scores dict\n",
    "                scores['EU_Variable'] = var1\n",
    "                scores['Japan_Variable'] = var2\n",
    "                scores['EU_Label'] = label1\n",
    "                scores['Japan_Label'] = label2\n",
    "                matched_vars.append(scores)\n",
    "\n",
    "            # Add the scores for this EU_Variable to the dataframe\n",
    "            scores_df = scores_df.append(pd.DataFrame(matched_vars), ignore_index=True)\n",
    "\n",
    "        # Set the order of the columns\n",
    "        columns_order = ['EU_Variable', 'EU_Label', 'Japan_Variable', 'Japan_Label'] + [func_name for func_name, _ in similarity_functions]\n",
    "        scores_df = scores_df[columns_order]\n",
    "\n",
    "        return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8537478",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu = pd.read_csv('EU_all_variables.csv')\n",
    "\n",
    "Jp= pd.read_csv('Japan_all_variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf791f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher= StringMatching(source=Jp,target=Eu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90232072",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df, scores_plot = matcher.multi_score(\n",
    "    n=5,\n",
    "    similarity_func=matcher.similarity_partial_ratio,\n",
    "    source_cols=['Variable', 'Label'],\n",
    "    target_cols=['Variable','Label'],\n",
    "    source_filter=('Variable', 'STUDYID')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac28ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result DataFrame:\")\n",
    "display(result_df)\n",
    "scores_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9686f8",
   "metadata": {},
   "source": [
    "# App\n",
    "# Please run the Class above first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f42898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\dash\\dash.py:516: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x22797f7cac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n",
      "Source DataFrame columns: Index(['Domain', 'Variable', 'Label', 'Type', 'Codes', 'Rule for derivation'], dtype='object')\n",
      "Target DataFrame columns: Index(['ADS Name', 'Variable', 'Label', 'Definition (derived Vars)', 'Type'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\suraj/.cache\\torch\\sentence_transformers\\bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7527ee64b14616a7918ec08332a0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cad620c9e24bdbab2c834f5ef824eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import dash_bootstrap_components as dbc\n",
    "import base64\n",
    "import datetime\n",
    "import io\n",
    "import dash\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import no_update\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash import dash_table\n",
    "from dash import dcc\n",
    "import plotly.express as px\n",
    "from dash import html\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets,\n",
    "                suppress_callback_exceptions=True)\n",
    "\n",
    "app.layout = html.Div([  # App layout opening\n",
    "\n",
    "    dcc.Tabs([  # Tabs opening\n",
    "\n",
    "        dcc.Tab(label='Upload', children=[\n",
    "            dcc.Loading(  # Loading opening\n",
    "                id=\"loading\",\n",
    "                type=\"circle\", \n",
    "                children=[  # Loading children opening\n",
    "                    dcc.Upload(  # Upload opening\n",
    "                        id='upload-data',\n",
    "                        children=html.Div([\n",
    "                            'Drag and Drop or ',\n",
    "                            html.A('Select Files')\n",
    "                        ]),\n",
    "                        style={\n",
    "                            'width': '100%',\n",
    "                            'height': '60px',\n",
    "                            'lineHeight': '60px',\n",
    "                            'borderWidth': '1px',\n",
    "                            'borderStyle': 'dashed',\n",
    "                            'borderRadius': '5px',\n",
    "                            'textAlign': 'center',\n",
    "                            'margin': '10px'\n",
    "                        },\n",
    "                        multiple=True\n",
    "                    ),  # Upload closing\n",
    "                    html.Div(id='output-div'),\n",
    "                ]  # Loading children closing\n",
    "            ),  # Loading closing\n",
    "        ]),\n",
    "\n",
    "        dcc.Tab(label='Data', children=[\n",
    "\n",
    "            html.Div(id='output-datatable'),\n",
    "        ]),\n",
    "\n",
    "        dcc.Tab(label='Matching', children=[\n",
    "            html.Div([\n",
    "                html.Label('Select similarity function:'),\n",
    "                dcc.Dropdown(\n",
    "                    id='similarity-function-dropdown',\n",
    "                    options=[\n",
    "                        {'label': 'similarity_ratio', 'value': 'similarity_ratio'},\n",
    "                        {'label': 'similarity_partial_ratio', 'value': 'similarity_partial_ratio'},\n",
    "                        {'label': 'similarity_token_sort_ratio', 'value': 'similarity_token_sort_ratio'},\n",
    "                        {'label': 'similarity_token_set_ratio', 'value': 'similarity_token_set_ratio'},\n",
    "                        {'label': 'similarity_partial_token_set_ratio', 'value': 'similarity_partial_token_set_ratio'},\n",
    "                        {'label': 'similarity_partial_token_sort_ratio', 'value': 'similarity_partial_token_sort_ratio'},\n",
    "                        {'label': 'QRatio', 'value': 'QRatio'},\n",
    "                        {'label': 'UQRatio', 'value': 'UQRatio'},\n",
    "                        {'label': 'UWRatio', 'value': 'UWRatio'},\n",
    "                        {'label': 'WRatio', 'value': 'WRatio'},\n",
    "                        {'label': 'tfidf_similarity', 'value': 'tfidf_similarity'},\n",
    "                        {'label': 'bert_similarity', 'value': 'bert_similarity'}],  # Uncomment if you want to include\n",
    "                    value='similarity_ratio'\n",
    "                ),\n",
    "            ]),\n",
    "             # Dropdown to select source file\n",
    "            html.Div([\n",
    "                html.Label('Select Source File:'),\n",
    "                dcc.Dropdown(\n",
    "                    id='source-file-dropdown',\n",
    "                    options=[],\n",
    "                    placeholder='Select Source File',\n",
    "                ),\n",
    "            ]),\n",
    "            # Dropdown to select target file\n",
    "            html.Div([\n",
    "                html.Label('Select Target File:'),\n",
    "                dcc.Dropdown(\n",
    "                    id='target-file-dropdown',\n",
    "                    options=[],\n",
    "                    placeholder='Select Target File',\n",
    "                ),\n",
    "            ]),\n",
    "            html.Div([\n",
    "                html.Label('Enter Source column name:'),\n",
    "                dcc.Input(\n",
    "                    id='source-column',\n",
    "                    type='text',\n",
    "                    placeholder='Enter source column name',\n",
    "                ),html.P(\"Example: Variable, Label (case matters)\", style={'color': 'grey'}),\n",
    "            ]),\n",
    "            html.Div([\n",
    "                html.Label('Enter Target column name:'),\n",
    "                dcc.Input(\n",
    "                    id='target-column',\n",
    "                    type='text',\n",
    "                    placeholder='Enter target column name',\n",
    "                ),html.P(\"Example: Variable, Label (case matters)\", style={'color': 'grey'}),\n",
    "            ]),\n",
    "            html.Div([\n",
    "                html.Label('Enter value to match:'),\n",
    "                dcc.Input(\n",
    "                    id='input-value',\n",
    "                    type='text',\n",
    "                    placeholder='Enter value to match',\n",
    "                ),html.P(\"Example: Column name,Variable in column - Variable, USDYID\", style={'color': 'grey'}),\n",
    "            ]),\n",
    "            html.Button('Run multi score', id='run-button', n_clicks=0),\n",
    "            html.Div(id='matching-output'),\n",
    "            html.H3(\"Scores Plot\"),\n",
    "            dcc.Graph(id='graph-output')\n",
    "        ])  # End of 'Matching' Tab\n",
    "    ]),  # End of Tabs\n",
    "\n",
    "    html.Div(id='store-container-1', style={'display': 'none'}),\n",
    "    html.Div(id='store-container-2', style={'display': 'none'}),\n",
    "    dcc.Store(id='store-df1'),\n",
    "    dcc.Store(id='store-df2')\n",
    "\n",
    "]) # end of layout\n",
    "#dictionary of the available methods if you decide to add more please update this \n",
    "similarity_functions = {\n",
    "    'similarity_ratio': StringMatching.similarity_ratio,\n",
    "    'similarity_partial_ratio': StringMatching.similarity_partial_ratio,\n",
    "    'similarity_token_sort_ratio': StringMatching.similarity_token_sort_ratio,\n",
    "    'similarity_token_set_ratio': StringMatching.similarity_token_set_ratio,\n",
    "    'similarity_partial_token_set_ratio': StringMatching.similarity_partial_token_set_ratio,\n",
    "    'similarity_partial_token_sort_ratio': StringMatching.similarity_partial_token_sort_ratio,\n",
    "    'QRatio': StringMatching.QRatio,\n",
    "    'UQRatio': StringMatching.UQRatio,\n",
    "    'UWRatio': StringMatching.UWRatio,\n",
    "    'WRatio': StringMatching.WRatio,\n",
    "    'tfidf_similarity': StringMatching.tfidf_similarity,\n",
    "    'bert_similarity': StringMatching.bert_similarity  # Uncomment if you want to include\n",
    "}\n",
    "\n",
    "# the callback and the method that updates the ouput in the- data tab\n",
    "@app.callback([Output('store-df1', 'data'), Output('store-df2', 'data'), Output('output-datatable', 'children')],\n",
    "              Input('upload-data', 'contents'),\n",
    "              State('upload-data', 'filename'),\n",
    "              State('upload-data', 'last_modified'))\n",
    "def update_output(list_of_contents, list_of_names, list_of_dates):\n",
    "    if list_of_contents is not None and len(list_of_contents) >= 2:\n",
    "        df1 = parse_contents(list_of_contents[0], list_of_names[0], list_of_dates[0])\n",
    "        df2 = parse_contents(list_of_contents[1], list_of_names[1], list_of_dates[1])\n",
    "        \n",
    "        if df1 is not None and df2 is not None:\n",
    "            children = html.Div([\n",
    "                html.H3(f\"{list_of_names[0]}\"),\n",
    "                dash_table.DataTable(\n",
    "                    id='table1',\n",
    "                    columns=[{\"name\": i, \"id\": i} for i in df1.columns],\n",
    "                    data=df1.to_dict('records'),\n",
    "                    filter_action='native', \n",
    "                    style_table={'overflowX': 'auto'},\n",
    "                    style_cell={\n",
    "                        'minWidth': '100px', 'width': '100px', 'maxWidth': '100px',\n",
    "                        'overflow': 'hidden',\n",
    "                        'textOverflow': 'ellipsis',\n",
    "                    },\n",
    "                    page_size=10, \n",
    "                    style_header={\n",
    "                        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                        'fontWeight': 'bold'\n",
    "                    },\n",
    "                    style_data_conditional=[\n",
    "                        {\n",
    "                            'if': {'state': 'active'}, \n",
    "                            'backgroundColor': 'rgba(0, 116, 217, 0.3)',\n",
    "                            'border': '1px solid rgb(0, 116, 217)'\n",
    "                        }\n",
    "                    ]\n",
    "                ),\n",
    "                html.H3(f\"{list_of_names[1]}\"),\n",
    "                dash_table.DataTable(\n",
    "                    id='table2',\n",
    "                    columns=[{\"name\": i, \"id\": i} for i in df2.columns],\n",
    "                    data=df2.to_dict('records'),\n",
    "                    filter_action='native', \n",
    "                    style_table={'overflowX': 'auto'},\n",
    "                    style_cell={\n",
    "                        'minWidth': '100px', 'width': '100px', 'maxWidth': '100px',\n",
    "                        'overflow': 'hidden',\n",
    "                        'textOverflow': 'ellipsis',\n",
    "                    },\n",
    "                    page_size=10, \n",
    "                    style_header={\n",
    "                        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                        'fontWeight': 'bold'\n",
    "                    },\n",
    "                    style_data_conditional=[\n",
    "                        {\n",
    "                            'if': {'state': 'active'}, \n",
    "                            'backgroundColor': 'rgba(0, 116, 217, 0.3)',\n",
    "                            'border': '1px solid rgb(0, 116, 217)'\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "            ])\n",
    "            return df1.to_dict('records'), df2.to_dict('records'), children\n",
    "\n",
    "    return dash.no_update, dash.no_update, dash.no_update\n",
    "\n",
    "#callback and method to run the muli_score function from the class this is what is triggered when the button is clicked - matching tab\n",
    "@app.callback(\n",
    "    [Output('matching-output', 'children'), Output('graph-output', 'figure')],\n",
    "    [Input('run-button', 'n_clicks')],\n",
    "    [State('similarity-function-dropdown', 'value'),\n",
    "     State('source-column', 'value'),\n",
    "     State('target-column', 'value'),\n",
    "     State('input-value', 'value'),\n",
    "     State('source-file-dropdown', 'value'),  # Add this State for source file dropdown\n",
    "     State('target-file-dropdown', 'value'),  # Add this State for target file dropdown\n",
    "     State('store-df1', 'data'),\n",
    "     State('store-df2', 'data'),\n",
    "     State('upload-data', 'filename')]  # Add this State for filenames\n",
    ")\n",
    "def run_multi_score(n_clicks, similarity_function, source_column, target_column, input_value,\n",
    "                    source_file, target_file, df1_data, df2_data, list_of_names):  \n",
    "    if n_clicks > 0:\n",
    "        logging.info('run_multi_score called with n_clicks=%s, similarity_function=%s', n_clicks, similarity_function)\n",
    "        try:\n",
    "            # convert input string to list of strings\n",
    "            source_cols = [col.strip() for col in source_column.split(',')]\n",
    "            target_cols = [col.strip() for col in target_column.split(',')]\n",
    "            # Determine which dataframe corresponds to the selected source and target files\n",
    "            if source_file == list_of_names[0].split('.')[0]:\n",
    "                source_df = pd.DataFrame(df1_data)\n",
    "                target_df= pd.DataFrame(df2_data)\n",
    "            else:\n",
    "                source_df = pd.DataFrame(df2_data)\n",
    "                target_df = pd.DataFrame(df1_data)\n",
    "            print(\"Source DataFrame columns:\", source_df.columns)\n",
    "            print(\"Target DataFrame columns:\", target_df.columns)\n",
    "            matcher = StringMatching(source_df, target_df)\n",
    "\n",
    "            # Parse the input value to separate column name and variable\n",
    "            input_column, input_variable = [val.strip() for val in input_value.split(',')]\n",
    "\n",
    "            # convert input_variable to appropriate type\n",
    "            dtype = source_df[input_column].dtype\n",
    "            if np.issubdtype(dtype, np.number):\n",
    "                input_variable = float(input_variable)\n",
    "            elif dtype == 'bool':\n",
    "                input_variable = bool(input_variable)\n",
    "\n",
    "            result_df, scores_plot = matcher.multi_score(\n",
    "                n=5,  \n",
    "                similarity_func=similarity_functions[similarity_function],\n",
    "                source_cols=source_cols,  \n",
    "                target_cols=target_cols,  \n",
    "                source_filter=(input_column, input_variable)\n",
    "            )# output format for the result\n",
    "            result_table = dash_table.DataTable(\n",
    "                    id='table',\n",
    "                    columns=[{\"name\": i, \"id\": i} for i in result_df.columns],\n",
    "                    data=result_df.to_dict('records'),\n",
    "                    filter_action='native', \n",
    "                    style_table={'overflowX': 'auto'},\n",
    "                    style_cell={\n",
    "                        'minWidth': '100px', 'width': '100px', 'maxWidth': '100px',\n",
    "                        'overflow': 'hidden',\n",
    "                        'textOverflow': 'ellipsis',\n",
    "                    },\n",
    "                    page_size=10, \n",
    "                    style_header={\n",
    "                        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                        'fontWeight': 'bold'\n",
    "                    },\n",
    "                    style_data_conditional=[\n",
    "                        {\n",
    "                            'if': {'state': 'active'}, \n",
    "                            'backgroundColor': 'rgba(0, 116, 217, 0.3)',\n",
    "                            'border': '1px solid rgb(0, 116, 217)'\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            return result_table, scores_plot\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error: {str(e)}\"\n",
    "            logging.error(error_message)\n",
    "            return html.Div([error_message]), dash.no_update\n",
    "    return dash.no_update, dash.no_update\n",
    "\n",
    "\n",
    "\n",
    "#parse content based on file upload\n",
    "def parse_contents(contents, filename, date):\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    try:\n",
    "        if 'csv' in filename:\n",
    "            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')),header=0)\n",
    "        elif 'xls' in filename:\n",
    "            df = pd.read_excel(io.BytesIO(decoded))\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    return df\n",
    "#this is the callback and hte method to update the drop down that helps get the names of the files- matching tab\n",
    "@app.callback(\n",
    "    Output('source-file-dropdown', 'options'),\n",
    "    Output('target-file-dropdown', 'options'),\n",
    "    [Input('upload-data', 'contents')],\n",
    "    [State('upload-data', 'filename')]\n",
    ")\n",
    "def update_file_dropdowns(list_of_contents, list_of_names):\n",
    "    if list_of_contents is not None and len(list_of_contents) >= 2:\n",
    "        file_options = [{'label': name.split('.')[0], 'value': name.split('.')[0]} for name in list_of_names]\n",
    "        return file_options, file_options\n",
    "    return [], []  # Empty options if no files uploaded\n",
    "\n",
    "\n",
    "\n",
    "# change the port number if the error says port already occupied\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False ,port=8050)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
